{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aa4c6f4-69e2-4edf-8014-719941fc34d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook is located in: C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python312\\Scripts\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "notebook_path = os.getcwd()\n",
    "print(\"Notebook is located in:\", notebook_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f8ab642-e955-42e1-8d01-82334f197b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 1: Imports and Load Data ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import load\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the log sequence matrix (already vectorized)\n",
    "X = load('log_sequence_matrix.joblib')\n",
    "\n",
    "# Optional: Standardize for models that need it\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b517bd6-85d5-4b37-88f0-77cd8c6c6610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 2: Helper to Convert Model Output to Binary Labels ===\n",
    "def convert_to_binary(predictions, anomaly_value=-1):\n",
    "    return np.where(predictions == anomaly_value, 1, 0)  # 1 = anomaly\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040e3437-51e7-4b63-b64e-1a7d29956127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 3: Run 5 Unsupervised Anomaly Detection Models ===\n",
    "\n",
    "# 1. Isolation Forest\n",
    "iso_model = IsolationForest(random_state=42)\n",
    "iso_preds = iso_model.fit_predict(X_scaled)\n",
    "iso_labels = convert_to_binary(iso_preds)\n",
    "\n",
    "# 2. Local Outlier Factor\n",
    "lof_model = LocalOutlierFactor(n_neighbors=20, contamination='auto')\n",
    "lof_preds = lof_model.fit_predict(X_scaled)\n",
    "lof_labels = convert_to_binary(lof_preds)\n",
    "\n",
    "# 3. One-Class SVM\n",
    "svm_model = OneClassSVM(nu=0.05, kernel='rbf', gamma='scale')\n",
    "svm_preds = svm_model.fit_predict(X_scaled)\n",
    "svm_labels = convert_to_binary(svm_preds)\n",
    "\n",
    "# 4. Elliptic Envelope\n",
    "ee_model = EllipticEnvelope(contamination=0.05)\n",
    "ee_preds = ee_model.fit_predict(X_scaled)\n",
    "ee_labels = convert_to_binary(ee_preds)\n",
    "\n",
    "# 5. DBSCAN\n",
    "dbscan_model = DBSCAN(eps=1.5, min_samples=5)\n",
    "dbscan_preds = dbscan_model.fit_predict(X_scaled)\n",
    "# Treat only noise (-1) as anomaly\n",
    "dbscan_labels = convert_to_binary(dbscan_preds, anomaly_value=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156b9cf4-7b15-4c07-ac5d-292462f288dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 4: Add Rule-Based Labels ===\n",
    "\n",
    "# Load original classified log sequences\n",
    "df_classified = pd.read_csv('classified_logs.csv')\n",
    "\n",
    "# Define anomaly event IDs\n",
    "anomalous_ids = ['E10', 'E11', 'E12']\n",
    "\n",
    "# Recreate windowed sequences\n",
    "event_ids = df_classified['EventId'].tolist()\n",
    "window_size = 3\n",
    "stride = 1\n",
    "windows = [\n",
    "    event_ids[i:i+window_size] \n",
    "    for i in range(0, len(event_ids) - window_size + 1, stride)\n",
    "]\n",
    "\n",
    "# Rule-based label: 1 if E10/11/12 present in window\n",
    "rule_labels = [\n",
    "    int(any(e in anomalous_ids for e in window)) \n",
    "    for window in windows\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd811634-f7db-4734-bc43-649e54ad427a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 5: Save All Labels to CSV ===\n",
    "\n",
    "# Combine into DataFrame\n",
    "labels_df = pd.DataFrame({\n",
    "    'rule_based': rule_labels,\n",
    "    'isolation_forest': iso_labels,\n",
    "    'local_outlier_factor': lof_labels,\n",
    "    'one_class_svm': svm_labels,\n",
    "    'elliptic_envelope': ee_labels,\n",
    "    'dbscan': dbscan_labels\n",
    "})\n",
    "\n",
    "# Add window index for traceability\n",
    "labels_df.index.name = 'window_index'\n",
    "\n",
    "# Save to CSV\n",
    "labels_df.to_csv('unsupervised_labels.csv')\n",
    "\n",
    "print(\"âœ… Unsupervised labelling complete. Saved to 'unsupervised_labels.csv'\")\n",
    "labels_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
